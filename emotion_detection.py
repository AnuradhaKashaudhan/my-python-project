# -*- coding: utf-8 -*-
"""Emotion_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17qBAn8GVUj2Y6RoXeSKxUkZi_urMEqGi
"""

!pip install opencv-python pandas tensorflow keras

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

# Update the path based on your Drive structure
file_path = '/content/drive/MyDrive/emotion_product_dataset.csv'

# Load dataset
df = pd.read_csv(file_path)

# Show top 5 rows
df.head()

df[df['emotion'] == 'Happy'].head()

emotion = "Sad"  # you can replace with detected emotion
recommendations = df[df['emotion'] == emotion].sample(5)
recommendations[['name', 'price', 'url']]

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install required packages
!pip install tensorflow

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Define the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(3, activation='softmax')  # 7 emotions: Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Summary
model.summary()

train_dir = "/content/drive/MyDrive/mini_fer_dataset/train"
test_dir = "/content/drive/MyDrive/mini_fer_dataset/test"

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)

train_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=(48, 48),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=4
)

test_data = test_datagen.flow_from_directory(
    test_dir,
    target_size=(48, 48),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=4
)

model.fit(
    train_data,
    validation_data=test_data,
    epochs=5  # You can increase to 10 if you want better training
)



model.save('/content/drive/MyDrive/emotion_model.h5')
print("‚úÖ Model saved to Google Drive")

from google.colab import drive
drive.mount('/content/drive')

train_dir = "/content/drive/MyDrive/mini_fer_dataset/train"
test_dir = "/content/drive/MyDrive/mini_fer_dataset/test"

from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rescale=1./255)

train_data = datagen.flow_from_directory(
    train_dir,
    target_size=(48, 48),
    color_mode='grayscale',
    class_mode='categorical'
)

test_data = datagen.flow_from_directory(
    test_dir,
    target_size=(48, 48),
    color_mode='grayscale',
    class_mode='categorical'
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(3, activation='softmax')  # Use 7 if full dataset, 3 for mini
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

model.fit(
    train_data,
    validation_data=test_data,
    epochs=5  # You can increase this
)

model.save('/content/drive/MyDrive/emotion_detection_model.h5')

from tensorflow.keras.models import load_model
model = load_model('/content/drive/MyDrive/emotion_detection_model.h5')

import pandas as pd

# Load the product dataset
df = pd.read_csv('/content/drive/MyDrive/emotion_product_dataset.csv')

# Preview the dataset
df.head()

import cv2
import numpy as np
import pandas as pd
import tensorflow as tf
from keras.models import load_model
from google.colab.patches import cv2_imshow

model = load_model('/content/drive/MyDrive/emotion_detection_model.h5')
df = pd.read_csv('/content/drive/MyDrive/emotion_product_dataset.csv')

print("‚úÖ Model and product data loaded")
print(df.head())

emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

def recommend_products(predicted_emotion, df, top_n=3):
    filtered_df = df[df['emotion'].str.lower() == predicted_emotion.lower()]
    return filtered_df.sample(n=min(top_n, len(filtered_df)))

emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

import numpy as np
import pandas as pd
from google.colab import files
from PIL import Image

# Load product data
df = pd.read_csv('/content/drive/MyDrive/emotion_product_dataset.csv')

# Define emotion labels
emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

# Upload image
uploaded = files.upload()

# Predict emotion for uploaded image
for fn in uploaded.keys():
    img = Image.open(fn).convert('L').resize((48, 48))
    img_array = np.array(img).reshape(1, 48, 48, 1) / 255.0

    pred = model.predict(img_array)
    predicted_emotion = emotion_labels[np.argmax(pred)]
    print(f"\nüß† Detected Emotion: {predicted_emotion}")

    print("\nüõçÔ∏è Recommended Products:")

    # Filter and show products for predicted emotion
    recs = df[df['emotion'] == predicted_emotion][['name', 'price', 'url']]
    for i, row in recs.iterrows():
        print(f"{row['name']} - ‚Çπ{row['price']} - {row['url']}")

from IPython.display import display, Javascript
from google.colab.output import eval_js
from IPython.display import Image
import cv2
import PIL.Image
import io
import numpy as np

# Function to capture image
def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
          const div = document.createElement('div');
          const capture = document.createElement('button');
          capture.textContent = 'üì∏ Take Photo';
          div.appendChild(capture);
          document.body.appendChild(div);

          const video = document.createElement('video');
          video.style.display = 'block';
          document.body.appendChild(video);

          const stream = await navigator.mediaDevices.getUserMedia({video: true});

          video.srcObject = stream;
          await video.play();

          // Resize the output to match the video stream
          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

          await new Promise((resolve) => capture.onclick = resolve);

          const canvas = document.createElement('canvas');
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          canvas.getContext('2d').drawImage(video, 0, 0);
          stream.getTracks().forEach(track => track.stop());
          div.remove();
          video.remove();

          const dataUrl = canvas.toDataURL('image/jpeg', quality);
          return dataUrl;
        }
    ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

from base64 import b64decode
filename = take_photo()
print(f"üì∏ Photo saved to {filename}")

# Load image and preprocess
from tensorflow.keras.preprocessing import image

img = image.load_img(filename, color_mode="grayscale", target_size=(48, 48))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0) / 255.0

# Predict emotion
pred = model.predict(img_array)
emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']
predicted_emotion = emotion_labels[np.argmax(pred)]
print("Detected Emotion:", predicted_emotion)

recommended_products = df[df['emotion'] == predicted_emotion]
recommended_products[['name', 'category', 'price', 'url']].head(5)

# Load the product dataset
import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/emotion_product_dataset.csv')  # make sure path matches your file

# Filter products based on predicted emotion
recommended_products = df[df['emotion'] == predicted_emotion]

# Show top 5 recommended products
print(f"\nüõçÔ∏è Top product recommendations for emotion: {predicted_emotion}\n")
recommended_products_display = recommended_products[['name', 'category', 'price', 'url']].head(5)
recommended_products_display

df = pd.read_csv('/content/drive/MyDrive/emotion_product_dataset.csv', encoding='utf-8-sig')
df.columns = df.columns.str.strip()  # Removes any leading/trailing spaces

print(df.columns)

df['image_url'].head(10).to_list()

df.columns = df.columns.str.lower().str.strip()